{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s2FldkySRPl",
        "outputId": "7aced832-2ca3-4547-e67f-37882bf9c7bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Collecting flask_cors\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pyngrok, flask_cors\n",
            "Successfully installed flask_cors-5.0.0 pyngrok-7.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install Flask pyngrok pandas scikit-learn flask_cors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZciyAklmh9jd"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "import threading\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "from flask_cors import CORS # uso do cors no ambiente local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HQhgJPjTiJ3o"
      },
      "outputs": [],
      "source": [
        "#imports para predição\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import joblib  # Para salvar e carregar modelos\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import GridSearchCV #- Grid Search para ajustar hiperparâmetros\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fBKSz9q1igbw"
      },
      "outputs": [],
      "source": [
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# Caminhos para os modelos salvos\n",
        "MODEL_GB_PATH = 'model_gb.joblib'\n",
        "MODEL_RF_PATH = 'model_rf.joblib'\n",
        "SCALER_PATH = 'scaler.joblib'\n",
        "\n",
        "@app.route('/process', methods=['POST'])\n",
        "def process_data():\n",
        "    # Verificar se o arquivo foi enviado\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({'error': 'No file part'}), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "    if file.filename == '':\n",
        "        return jsonify({'error': 'No selected file'}), 400\n",
        "\n",
        "    try:\n",
        "        # Carregar a planilha enviada\n",
        "        data = pd.read_csv(file, delimiter=';')\n",
        "\n",
        "        # Remover espaços extras ao redor dos nomes das colunas\n",
        "        data.columns = data.columns.str.strip()\n",
        "\n",
        "        # Converter as colunas que precisam de conversão\n",
        "        data['CA'] = data['CA'].str.replace(',', '.').astype(float)\n",
        "        data['peso'] = pd.to_numeric(data['peso'].str.replace(',', '.'), errors='coerce')\n",
        "        data['ValorRecebido'] = pd.to_numeric(data['ValorRecebido'].str.replace(',', '.'), errors='coerce')\n",
        "        data['bonificacaoEmpresa'] = pd.to_numeric(data['bonificacaoEmpresa'].str.replace(',', '.'), errors='coerce')\n",
        "        data['CreditoMortalidade'] = pd.to_numeric(data['CreditoMortalidade'].str.replace(',', '.'), errors='coerce')\n",
        "        data['Descontos'] = pd.to_numeric(data['Descontos'].str.replace(',', '.'), errors='coerce')\n",
        "\n",
        "        # Criação de variáveis derivadas necessárias\n",
        "        data['Temp_Umidade'] = data['Temperatura'] * data['Umidade']\n",
        "        data['Temp_QualidadeSolo'] = data['Temperatura'] * data['QualidadeSolo']\n",
        "        data['Temp_Infraestrutura'] = data['Temperatura'] * data['Infraestrutura']\n",
        "        data['Umidade_QualidadeSolo'] = data['Umidade'] * data['QualidadeSolo']\n",
        "        data['Umidade_Infraestrutura'] = data['Umidade'] * data['Infraestrutura']\n",
        "        data['QualidadeSolo_Infraestrutura'] = data['QualidadeSolo'] * data['Infraestrutura']\n",
        "        data['CA_peso'] = data['CA'] * data['peso']\n",
        "\n",
        "        # Selecione as colunas que serão usadas como features\n",
        "        features = [\n",
        "            'Capacidade', 'peso', 'diasTratamento', 'bonificacaoEmpresa',\n",
        "            'Descontos', 'CreditoMortalidade', 'Temperatura', 'Umidade',\n",
        "            'QualidadeSolo', 'Infraestrutura', 'CA',\n",
        "            'Temp_Umidade', 'Temp_QualidadeSolo', 'Temp_Infraestrutura',\n",
        "            'Umidade_QualidadeSolo', 'Umidade_Infraestrutura',\n",
        "            'QualidadeSolo_Infraestrutura', 'CA_peso'\n",
        "        ]\n",
        "\n",
        "        X = data[features]\n",
        "        y = data['ValorRecebido']\n",
        "\n",
        "        # Verificar se o scaler já existe\n",
        "        if os.path.exists(SCALER_PATH):\n",
        "            scaler = joblib.load(SCALER_PATH)\n",
        "        else:\n",
        "            scaler = StandardScaler()\n",
        "            joblib.dump(scaler, SCALER_PATH)\n",
        "\n",
        "        # Normalizando as características\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        # Verificando se os modelos já foram treinados e salvos\n",
        "        if os.path.exists(MODEL_GB_PATH) and os.path.exists(MODEL_RF_PATH):\n",
        "            model_gb = joblib.load(MODEL_GB_PATH)\n",
        "            model_rf = joblib.load(MODEL_RF_PATH)\n",
        "        else:\n",
        "            # Dividisão dos dados\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Treinar o modelo (Gradient Boosting)\n",
        "            model_gb = GradientBoostingRegressor()\n",
        "            model_gb.fit(X_train, y_train)\n",
        "\n",
        "            # Treinar e avaliar o modelo Random Forest\n",
        "            model_rf = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)\n",
        "            model_rf.fit(X_train, y_train)\n",
        "\n",
        "            # Salvar os modelos treinados\n",
        "            joblib.dump(model_gb, MODEL_GB_PATH)\n",
        "            joblib.dump(model_rf, MODEL_RF_PATH)\n",
        "\n",
        "\n",
        "        # Fazendo as previsões com os modelos salvos\n",
        "        data['ValorPrevisto_GB'] = model_gb.predict(scaler.transform(X))\n",
        "        data['ValorPrevisto_RF'] = model_rf.predict(scaler.transform(X))\n",
        "\n",
        "        # Filtrando os dados por capacidade\n",
        "        data_20000 = data[data['Capacidade'] == 20000]\n",
        "        data_40000 = data[data['Capacidade'] == 40000]\n",
        "        data_8000 = data[data['Capacidade'] == 8000]\n",
        "\n",
        "        # Retornando os resultados como JSON\n",
        "        return jsonify({\n",
        "            'data_20000': data_20000.to_dict(orient='records'),\n",
        "            'data_40000': data_40000.to_dict(orient='records'),\n",
        "            'data_8000': data_8000.to_dict(orient='records')\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrBNIAl8Rmub",
        "outputId": "ef89cb13-cfe9-432f-8ca9-f990dd547edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken #remova o comentário e informe o token ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZieYZ3kuogD",
        "outputId": "dcb3fbed-8073-4927-828d-d1ec605c28c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok URL: NgrokTunnel: \"https://633c-35-237-111-3.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Nov/2024 23:51:59] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Nov/2024 23:52:21] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Nov/2024 23:52:42] \"POST /process HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "# Expor o app Flask usando ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\" * ngrok URL: {public_url}\")\n",
        "\n",
        "# Rodar o Flask\n",
        "app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFaKSL2PitB2"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}